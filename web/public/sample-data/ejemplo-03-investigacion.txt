Notas de Investigación: Modelos LLM para Edge Computing

Fuentes consultadas:
- https://arxiv.org/abs/2401.12345 (Paper sobre cuantización)
- https://huggingface.co/models (catálogo de modelos)
- https://ollama.com/library (modelos optimizados)

Hallazgos principales:
Los modelos cuantizados Q4 reducen el tamaño hasta 75% con pérdida de precisión <2%. 
Qwen3-14B muestra mejor rendimiento en español que Llama 3.1 8B.

Contactos expertos:
- Dr. Roberto Sánchez (roberto.sanchez@universidad.edu)
- Investigador en NLP, papers relevantes sobre RAG

Próximos pasos:
1. Benchmark Qwen3 vs Mistral en español
2. Medir latencia en CPU vs GPU
3. Evaluar context window óptimo (4k vs 8k tokens)

Keywords: LLM, cuantización, edge computing, NLP, investigación